# Sentiric XTTS v2 Microservice

Production-ready, GPU-accelerated Text-to-Speech microservice based on Coqui XTTS v2. Supports multilingual synthesis, voice cloning, SSML control, and streaming capabilities via REST API and Gradio UI.

## Features

- üöÄ **High Performance:** Async inference engine with GPU locking mechanisms (RTF ~0.0012).
- üê≥ **Docker Ready:** Full NVIDIA GPU passthrough support with `docker-compose`.
- ‚ö° **Low Latency Streaming:** Optimized chunking architecture delivering TTFB < 500ms.
- üõ°Ô∏è **Enterprise Security:** 
  - **XML Bomb Protection:** SSML parsing via `defusedxml`.
  - **Non-Blocking I/O:** Async file operations preventing event loop blocking.
- üó£Ô∏è **Advanced Control:** Full SSML support (pause, emphasis, prosody/speed).
- üíæ **Smart Caching:** MD5-based latent caching for repeated requests.

## Prerequisites

- **Docker** & **Docker Compose**
- **NVIDIA Drivers** & **NVIDIA Container Toolkit** (for GPU support)
- *Optional:* Python 3.10+ (for local development)

## Quick Start (Docker)

1. **Clone & Config:**
   ```bash
   git clone <repo_url>
   cd sentiric-tts-coqui-service
   cp .env.example .env
   ```

2. **Run Service:**
   ```bash
   make build
   make up
   ```
   *Note: First run will download ~3GB model data. Check logs:* `make logs`

3. **Access:**
   - **Swagger API:** [http://localhost:14030/docs](http://localhost:14030/docs)
   - **Dashboard:** [http://localhost:14030/](http://localhost:14030/)

## API Usage

### 1. Basic TTS (Standard Voice)
```bash
curl -X POST "http://localhost:14030/api/tts" \
     -H "Content-Type: application/json" \
     -d '{
           "text": "Hello, this is a production ready service.",
           "language": "en",
           "speaker_idx": "Ana Florence",
           "temperature": 0.7
         }' \
     --output output.wav
```

### 2. SSML Control
```xml
<speak>
    Hello <break time="1s"/> 
    <prosody rate="fast">I am speaking fast now.</prosody>
    <emphasis level="strong">This is important.</emphasis>
</speak>
```

### 3. Voice Cloning
```bash
curl -X POST "http://localhost:14030/api/tts/clone" \
     -F "text=I am speaking with your voice now." \
     -F "language=en" \
     -F "files=@/path/to/your/sample_voice.wav" \
     --output cloned_output.wav
```

## Architecture

The system follows a strict SRP (Single Responsibility Principle) architecture:

- **Engine (`app/core/engine.py`):** Singleton class handling Model memory management and Thread-Safe inference locking.
- **SSML Handler (`app/core/ssml_handler.py`):** Secure XML parsing logic isolated from the engine.
- **Audio Processor (`app/core/audio.py`):** FFmpeg wrapper for format conversion and normalization (EBU R128).
- **API (`app/main.py`):** FastAPI endpoints exposing the engine via async non-blocking routes.
- **UI:** Custom HTML5/JS Dashboard with AudioContext API visualization.

## Performance Benchmarks

| Metric | Result | Target | Status |
| :--- | :--- | :--- | :--- |
| **RTF (Real-Time Factor)** | `0.0012` | < 0.30 | ‚úÖ PASS |
| **Streaming Latency (TTFB)** | `471 ms` | < 500 ms | ‚úÖ PASS |
| **Concurrency Stability** | `100%` | 100% | ‚úÖ STABLE |

## Troubleshooting

- **CUDA Error:** Ensure `nvidia-smi` works on host and `nvidia-container-toolkit` is installed.
- **Download Stuck:** Check internet connection. Models are saved in `./data/models`.

